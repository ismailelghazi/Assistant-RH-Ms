{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# HR Employee Attrition Model Training\n",
                "\n",
                "This notebook trains the XGBoost Classifier model used for the HR Prediction App.\n",
                "It covers:\n",
                "1. Data Loading (or Synthetic Generation)\n",
                "2. Preprocessing (Label Encoding)\n",
                "3. Model Training (XGBoost)\n",
                "4. Evolution\n",
                "5. Exporting Model & Preprocessor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import joblib\n",
                "import xgboost as xgb\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import accuracy_score, classification_report\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from pathlib import Path\n",
                "import sys\n",
                "\n",
                "# Add src to path\n",
                "sys.path.append('../src')\n",
                "from config import COLUMNS_TO_DROP, CATEGORICAL_COLUMNS, NUMERICAL_COLUMNS, MODELS_DIR, DATA_DIR"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data\n",
                "If no data exists, we generate synthetic data for demonstration."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_synthetic_data(n=1000):\n",
                "    np.random.seed(42)\n",
                "    data = {\n",
                "        'Age': np.random.randint(18, 60, n),\n",
                "        'DailyRate': np.random.randint(100, 1500, n),\n",
                "        'DistanceFromHome': np.random.randint(1, 30, n),\n",
                "        'Education': np.random.randint(1, 6, n),\n",
                "        'EnvironmentSatisfaction': np.random.randint(1, 5, n),\n",
                "        'HourlyRate': np.random.randint(30, 100, n),\n",
                "        'JobInvolvement': np.random.randint(1, 5, n),\n",
                "        'JobLevel': np.random.randint(1, 6, n),\n",
                "        'JobSatisfaction': np.random.randint(1, 5, n),\n",
                "        'MonthlyIncome': np.random.randint(2000, 20000, n),\n",
                "        'MonthlyRate': np.random.randint(2000, 27000, n),\n",
                "        'NumCompaniesWorked': np.random.randint(0, 10, n),\n",
                "        'PercentSalaryHike': np.random.randint(11, 26, n),\n",
                "        'PerformanceRating': np.random.randint(3, 5, n),\n",
                "        'RelationshipSatisfaction': np.random.randint(1, 5, n),\n",
                "        'StockOptionLevel': np.random.randint(0, 4, n),\n",
                "        'TotalWorkingYears': np.random.randint(0, 40, n),\n",
                "        'TrainingTimesLastYear': np.random.randint(0, 7, n),\n",
                "        'WorkLifeBalance': np.random.randint(1, 5, n),\n",
                "        'YearsAtCompany': np.random.randint(0, 20, n),\n",
                "        'YearsInCurrentRole': np.random.randint(0, 15, n),\n",
                "        'YearsSinceLastPromotion': np.random.randint(0, 15, n),\n",
                "        'YearsWithCurrManager': np.random.randint(0, 15, n),\n",
                "        # Categorical\n",
                "        'BusinessTravel': np.random.choice(['Travel_Rarely', 'Travel_Frequently', 'Non-Travel'], n),\n",
                "        'Department': np.random.choice(['Sales', 'Research & Development', 'Human Resources'], n),\n",
                "        'EducationField': np.random.choice(['Life Sciences', 'Medical', 'Marketing', 'Technical Degree', 'Other'], n),\n",
                "        'Gender': np.random.choice(['Male', 'Female'], n),\n",
                "        'JobRole': np.random.choice(['Sales Executive', 'Research Scientist', 'Laboratory Technician', 'Manufacturing Director'], n),\n",
                "        'MaritalStatus': np.random.choice(['Single', 'Married', 'Divorced'], n),\n",
                "        'OverTime': np.random.choice(['Yes', 'No'], n),\n",
                "        # Target\n",
                "        'Attrition': np.random.choice([0, 1], n, p=[0.84, 0.16])\n",
                "    }\n",
                "    return pd.DataFrame(data)\n",
                "\n",
                "# Check if file exists, else create\n",
                "data_path = DATA_DIR / \"HR_Employee_Attrition.csv\"\n",
                "if data_path.exists():\n",
                "    df = pd.read_csv(data_path)\n",
                "else:\n",
                "    print(\"Data file not found. Generating synthetic data...\")\n",
                "    df = generate_synthetic_data()\n",
                "    \n",
                "print(f\"Data Shape: {df.shape}\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Drop useless columns\n",
                "df_clean = df.drop(columns=[c for c in COLUMNS_TO_DROP if c in df.columns], errors='ignore')\n",
                "\n",
                "# Encode Categorical\n",
                "encoders = {}\n",
                "for col in CATEGORICAL_COLUMNS:\n",
                "    if col in df_clean.columns:\n",
                "        le = LabelEncoder()\n",
                "        df_clean[col] = le.fit_transform(df_clean[col])\n",
                "        encoders[col] = le\n",
                "\n",
                "# Encode Target\n",
                "target_col = 'Attrition'\n",
                "if df_clean[target_col].dtype == 'object':\n",
                "    df_clean[target_col] = df_clean[target_col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
                "\n",
                "X = df_clean.drop(columns=[target_col])\n",
                "y = df_clean[target_col]\n",
                "\n",
                "print(\"Preprocessing complete.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Train Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "model = xgb.XGBClassifier(\n",
                "    n_estimators=100,\n",
                "    max_depth=5,\n",
                "    learning_rate=0.1,\n",
                "    use_label_encoder=False,\n",
                "    eval_metric='logloss'\n",
                ")\n",
                "\n",
                "model.fit(X_train, y_train)\n",
                "\n",
                "# Evaluate\n",
                "y_pred = model.predict(X_test)\n",
                "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
                "print(classification_report(y_test, y_pred))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Save Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save Model Artifacts\n",
                "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "model_data = {\n",
                "    'model': model,\n",
                "    'model_name': 'XGBoost_v1',\n",
                "    'metrics': {'accuracy': accuracy_score(y_test, y_pred)}\n",
                "}\n",
                "\n",
                "preprocessor_data = {\n",
                "    'preprocessor': encoders,  # In this simple case, just label encoders\n",
                "    'feature_names': list(X.columns)\n",
                "}\n",
                "\n",
                "joblib.dump(model_data, MODELS_DIR / \"best_model.pkl\")\n",
                "joblib.dump(preprocessor_data, MODELS_DIR / \"preprocessor.pkl\")\n",
                "\n",
                "print(f\"Model saved to {MODELS_DIR}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}